{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w7cJVg3ApDEN"
   },
   "source": [
    "# Download data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xUk0uccUo_2V"
   },
   "source": [
    "Downloading the ECG 2020 datasets and copy to google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IbqUTEzJo85j"
   },
   "outputs": [],
   "source": [
    "# !wget -r -N -c -np https://physionet.org/files/ptb-xl/1.0.1/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JaIMyWsp7U4c"
   },
   "outputs": [],
   "source": [
    "# %cp -r -np /content/physionet.org/files/ptb-xl /content/gdrive/My\\ Drive/ECG2020new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OIswKtMh2-uE"
   },
   "outputs": [],
   "source": [
    "# #%cd /content/physionet.org/files/ptb-xl/\n",
    "# %cd 20000/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L52oKq77TVDE"
   },
   "outputs": [],
   "source": [
    "# %ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vwtoU0gUVD37"
   },
   "outputs": [],
   "source": [
    "# %pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6OBbq-jl7fz0"
   },
   "outputs": [],
   "source": [
    "#%cd physionet.org/files/ptb-xl/1.0.1/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A8iTcIwQC7HE"
   },
   "source": [
    "Load GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z8f7WTLYC8yB",
    "outputId": "81b79581-63d1-41e6-b5d4-ffaaeeed6b9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3RPKHZKx-geM"
   },
   "source": [
    "# Link to Google Drive Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jgqPUO1ypCfE",
    "outputId": "24bf41bc-38b6-4e0a-d4d1-b3c18d8f976f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rp-L-NTRtO_m"
   },
   "source": [
    "Install library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YvhISaIPtHKE",
    "outputId": "75843dcf-46bf-4264-fb1a-571a789a431b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wfdb\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/99/4b4749925cf4123643b512e27710bfaad4f048eba8b840c581780e2aada9/wfdb-3.2.0-py3-none-any.whl (119kB)\n",
      "\r",
      "\u001b[K     |██▊                             | 10kB 14.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████▌                          | 20kB 20.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████▎                       | 30kB 25.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 40kB 20.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▊                  | 51kB 15.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▌               | 61kB 13.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▏            | 71kB 14.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 81kB 13.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▊       | 92kB 14.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▍    | 102kB 15.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▏ | 112kB 15.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 122kB 15.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.4 in /usr/local/lib/python3.7/dist-packages (from wfdb) (2.4.7)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from wfdb) (2018.9)\n",
      "Requirement already satisfied: idna>=2.2 in /usr/local/lib/python3.7/dist-packages (from wfdb) (2.10)\n",
      "Requirement already satisfied: urllib3>=1.22 in /usr/local/lib/python3.7/dist-packages (from wfdb) (1.24.3)\n",
      "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from wfdb) (1.3.1)\n",
      "Requirement already satisfied: requests>=2.8.1 in /usr/local/lib/python3.7/dist-packages (from wfdb) (2.23.0)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wfdb) (3.2.2)\n",
      "Requirement already satisfied: certifi>=2016.8.2 in /usr/local/lib/python3.7/dist-packages (from wfdb) (2020.12.5)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from wfdb) (0.22.2.post1)\n",
      "Collecting threadpoolctl>=1.0.0\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.10.1 in /usr/local/lib/python3.7/dist-packages (from wfdb) (1.19.5)\n",
      "Requirement already satisfied: chardet>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from wfdb) (3.0.4)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from wfdb) (1.4.1)\n",
      "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from wfdb) (0.10.0)\n",
      "Requirement already satisfied: pandas>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from wfdb) (1.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.4.2 in /usr/local/lib/python3.7/dist-packages (from wfdb) (2.8.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from wfdb) (1.0.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10.0->wfdb) (1.15.0)\n",
      "Installing collected packages: threadpoolctl, wfdb\n",
      "Successfully installed threadpoolctl-2.1.0 wfdb-3.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install wfdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K_2GXVmxtSZL"
   },
   "source": [
    "Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "laLZqeyZtRs0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wfdb\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TR7dtEngEOeR"
   },
   "source": [
    "# Get the label from csv, set up the basic raw data, get the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fr6mSieesLoT"
   },
   "outputs": [],
   "source": [
    "#get path\n",
    "path='/content/gdrive/My Drive/ECG2020/1.0.1/'\n",
    "# path = '/content/gdrive/.shortcut-targets-by-id/1ca8px2VUzY6uBCgo13kYoW0_JuynXfG7/1.0.1/'\n",
    "tf_save_path = '/content/gdrive/My Drive/tfrecord/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ez1KTXIoqLkg"
   },
   "outputs": [],
   "source": [
    "def get_label_info(path):\n",
    "  def add_path(str2):\n",
    "      return path + str2\n",
    "  def aggregate_diagnostic(y_dic):\n",
    "      tmp = []\n",
    "      for key in y_dic.keys():\n",
    "          if key in agg_df.index:\n",
    "              tmp.append(agg_df.loc[key].diagnostic_class)\n",
    "      if len(tmp) == 0:\n",
    "        return \"NL\"\n",
    "      return list(set(tmp))[0]\n",
    "  Y = pd.read_csv(path+'ptbxl_database.csv', index_col='ecg_id')\n",
    "  Y.scp_codes = Y.scp_codes.apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "      # Load scp_statements.csv for diagnostic aggregation\n",
    "  agg_df = pd.read_csv(path+'scp_statements.csv', index_col=0)\n",
    "  agg_df = agg_df[agg_df.diagnostic == 1]\n",
    "\n",
    "      # Apply diagnostic superclass\n",
    "      #target label of the classification\n",
    "  Y['diagnostic_superclass'] = Y.scp_codes.apply(aggregate_diagnostic)\n",
    "  Y['new_filename'] = Y.filename_hr.map(add_path)\n",
    "  return Y[[\"new_filename\",\"diagnostic_superclass\",\"age\",\"sex\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "joumwM6zqLnM",
    "outputId": "98a0434c-3d23-4a07-f7e9-7a3c23d55d00"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_filename</th>\n",
       "      <th>diagnostic_superclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecg_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/content/gdrive/My Drive/ECG2020/1.0.1/records...</td>\n",
       "      <td>NORM</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/content/gdrive/My Drive/ECG2020/1.0.1/records...</td>\n",
       "      <td>NORM</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/content/gdrive/My Drive/ECG2020/1.0.1/records...</td>\n",
       "      <td>NORM</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/content/gdrive/My Drive/ECG2020/1.0.1/records...</td>\n",
       "      <td>NORM</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/content/gdrive/My Drive/ECG2020/1.0.1/records...</td>\n",
       "      <td>NORM</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21833</th>\n",
       "      <td>/content/gdrive/My Drive/ECG2020/1.0.1/records...</td>\n",
       "      <td>STTC</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21834</th>\n",
       "      <td>/content/gdrive/My Drive/ECG2020/1.0.1/records...</td>\n",
       "      <td>NORM</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21835</th>\n",
       "      <td>/content/gdrive/My Drive/ECG2020/1.0.1/records...</td>\n",
       "      <td>STTC</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21836</th>\n",
       "      <td>/content/gdrive/My Drive/ECG2020/1.0.1/records...</td>\n",
       "      <td>NORM</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21837</th>\n",
       "      <td>/content/gdrive/My Drive/ECG2020/1.0.1/records...</td>\n",
       "      <td>NORM</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21837 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             new_filename  ... sex\n",
       "ecg_id                                                     ...    \n",
       "1       /content/gdrive/My Drive/ECG2020/1.0.1/records...  ...   1\n",
       "2       /content/gdrive/My Drive/ECG2020/1.0.1/records...  ...   0\n",
       "3       /content/gdrive/My Drive/ECG2020/1.0.1/records...  ...   1\n",
       "4       /content/gdrive/My Drive/ECG2020/1.0.1/records...  ...   0\n",
       "5       /content/gdrive/My Drive/ECG2020/1.0.1/records...  ...   1\n",
       "...                                                   ...  ...  ..\n",
       "21833   /content/gdrive/My Drive/ECG2020/1.0.1/records...  ...   1\n",
       "21834   /content/gdrive/My Drive/ECG2020/1.0.1/records...  ...   0\n",
       "21835   /content/gdrive/My Drive/ECG2020/1.0.1/records...  ...   1\n",
       "21836   /content/gdrive/My Drive/ECG2020/1.0.1/records...  ...   1\n",
       "21837   /content/gdrive/My Drive/ECG2020/1.0.1/records...  ...   0\n",
       "\n",
       "[21837 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = get_label_info(path)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_SSofaTgqSok",
    "outputId": "d5c21531-1249-4edc-d800-a8332b910ab0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NORM    9490\n",
       "STTC    5250\n",
       "MI      4042\n",
       "CD      1709\n",
       "HYP      939\n",
       "NL       407\n",
       "Name: diagnostic_superclass, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y[y.diagnostic_superclass !=\"DELETE\"]\n",
    "y.diagnostic_superclass.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1s0NvCVfqTUF",
    "outputId": "b491481c-99af-4f37-9433-2e3adb008645"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NORM    9484\n",
       "STTC    5211\n",
       "MI      4020\n",
       "CD      1695\n",
       "HYP      935\n",
       "NL       403\n",
       "Name: diagnostic_superclass, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.dropna(how='any',axis=0) \n",
    "y.diagnostic_superclass.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C3eDhw444C2-"
   },
   "source": [
    "Convert the label into numercial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vhOyNSQc0vRY"
   },
   "outputs": [],
   "source": [
    "numeric_label = {\"diagnostic_superclass\":{\"NORM\":0,\"CD\":1,\"MI\":2,\"STTC\":3,\"HYP\":4,\"NL\":5}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "LDFYUUw60vT-",
    "outputId": "6228c1cf-f5d1-4c85-eb76-ee5ef6b9e599"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_filename</th>\n",
       "      <th>diagnostic_superclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecg_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/content/gdrive/My Drive/ECG2020/1.0.1/records...</td>\n",
       "      <td>0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/content/gdrive/My Drive/ECG2020/1.0.1/records...</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/content/gdrive/My Drive/ECG2020/1.0.1/records...</td>\n",
       "      <td>0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/content/gdrive/My Drive/ECG2020/1.0.1/records...</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/content/gdrive/My Drive/ECG2020/1.0.1/records...</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21833</th>\n",
       "      <td>/content/gdrive/My Drive/ECG2020/1.0.1/records...</td>\n",
       "      <td>3</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21834</th>\n",
       "      <td>/content/gdrive/My Drive/ECG2020/1.0.1/records...</td>\n",
       "      <td>0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21835</th>\n",
       "      <td>/content/gdrive/My Drive/ECG2020/1.0.1/records...</td>\n",
       "      <td>3</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21836</th>\n",
       "      <td>/content/gdrive/My Drive/ECG2020/1.0.1/records...</td>\n",
       "      <td>0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21837</th>\n",
       "      <td>/content/gdrive/My Drive/ECG2020/1.0.1/records...</td>\n",
       "      <td>0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21748 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             new_filename  ...  sex\n",
       "ecg_id                                                     ...     \n",
       "1       /content/gdrive/My Drive/ECG2020/1.0.1/records...  ...    1\n",
       "2       /content/gdrive/My Drive/ECG2020/1.0.1/records...  ...    0\n",
       "3       /content/gdrive/My Drive/ECG2020/1.0.1/records...  ...    1\n",
       "4       /content/gdrive/My Drive/ECG2020/1.0.1/records...  ...    0\n",
       "5       /content/gdrive/My Drive/ECG2020/1.0.1/records...  ...    1\n",
       "...                                                   ...  ...  ...\n",
       "21833   /content/gdrive/My Drive/ECG2020/1.0.1/records...  ...    1\n",
       "21834   /content/gdrive/My Drive/ECG2020/1.0.1/records...  ...    0\n",
       "21835   /content/gdrive/My Drive/ECG2020/1.0.1/records...  ...    1\n",
       "21836   /content/gdrive/My Drive/ECG2020/1.0.1/records...  ...    1\n",
       "21837   /content/gdrive/My Drive/ECG2020/1.0.1/records...  ...    0\n",
       "\n",
       "[21748 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.replace(numeric_label)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ur3lVPko0eN"
   },
   "source": [
    "Resampling the data label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I2513wewpOv2",
    "outputId": "4dba807b-477d-408d-ae89-011c60051b35"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    5000\n",
       "3    5000\n",
       "2    5000\n",
       "1    5000\n",
       "0    5000\n",
       "Name: diagnostic_superclass, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#up sampling the miniority class of train dataset\n",
    "\n",
    "df_0 = y[y.diagnostic_superclass==0]\n",
    "df_1 = y[y.diagnostic_superclass==1]\n",
    "df_2 = y[y.diagnostic_superclass==2]\n",
    "df_3 = y[y.diagnostic_superclass==3]\n",
    "df_4 = y[y.diagnostic_superclass==4]\n",
    "df_0 = resample(df_0, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=5000,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    "df_1 = resample(df_1, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=5000,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    "df_2 = resample(df_2, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=5000,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    "df_3 = resample(df_3, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=5000,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    "df_4 = resample(df_4, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=5000,    # to match majority class\n",
    "                                 random_state=123) # reproducible results                                \n",
    "df_ = pd.concat([df_0,df_1,df_2,df_3,df_4],ignore_index=True)\n",
    "df_.diagnostic_superclass.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "bZep9MxepOyi",
    "outputId": "1336fc2e-b158-42d3-d1e5-6eb2ee6db05c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>new_filename</th>\n",
       "      <th>diagnostic_superclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22064</td>\n",
       "      <td>/content/gdrive/My Drive/ECG2020/1.0.1/records...</td>\n",
       "      <td>4</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20656</td>\n",
       "      <td>/content/gdrive/My Drive/ECG2020/1.0.1/records...</td>\n",
       "      <td>4</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4172</td>\n",
       "      <td>/content/gdrive/My Drive/ECG2020/1.0.1/records...</td>\n",
       "      <td>0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19107</td>\n",
       "      <td>/content/gdrive/My Drive/ECG2020/1.0.1/records...</td>\n",
       "      <td>3</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22160</td>\n",
       "      <td>/content/gdrive/My Drive/ECG2020/1.0.1/records...</td>\n",
       "      <td>4</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>7471</td>\n",
       "      <td>/content/gdrive/My Drive/ECG2020/1.0.1/records...</td>\n",
       "      <td>1</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>23970</td>\n",
       "      <td>/content/gdrive/My Drive/ECG2020/1.0.1/records...</td>\n",
       "      <td>4</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>17305</td>\n",
       "      <td>/content/gdrive/My Drive/ECG2020/1.0.1/records...</td>\n",
       "      <td>3</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>19586</td>\n",
       "      <td>/content/gdrive/My Drive/ECG2020/1.0.1/records...</td>\n",
       "      <td>3</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>23917</td>\n",
       "      <td>/content/gdrive/My Drive/ECG2020/1.0.1/records...</td>\n",
       "      <td>4</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                       new_filename  ...   age  sex\n",
       "0      22064  /content/gdrive/My Drive/ECG2020/1.0.1/records...  ...  46.0    0\n",
       "1      20656  /content/gdrive/My Drive/ECG2020/1.0.1/records...  ...  39.0    0\n",
       "2       4172  /content/gdrive/My Drive/ECG2020/1.0.1/records...  ...  75.0    0\n",
       "3      19107  /content/gdrive/My Drive/ECG2020/1.0.1/records...  ...  40.0    1\n",
       "4      22160  /content/gdrive/My Drive/ECG2020/1.0.1/records...  ...  80.0    1\n",
       "...      ...                                                ...  ...   ...  ...\n",
       "24995   7471  /content/gdrive/My Drive/ECG2020/1.0.1/records...  ...  70.0    1\n",
       "24996  23970  /content/gdrive/My Drive/ECG2020/1.0.1/records...  ...  82.0    1\n",
       "24997  17305  /content/gdrive/My Drive/ECG2020/1.0.1/records...  ...  72.0    1\n",
       "24998  19586  /content/gdrive/My Drive/ECG2020/1.0.1/records...  ...  71.0    1\n",
       "24999  23917  /content/gdrive/My Drive/ECG2020/1.0.1/records...  ...  76.0    1\n",
       "\n",
       "[25000 rows x 5 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shuffle the dataframe and re_index the dataset\n",
    "def shuffle_dataset(df):\n",
    "  df = df.sample(frac=1)\n",
    "  df = df.reset_index()\n",
    "  return df\n",
    "shuffle_dataset(df_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "6jWjUQS7pO1C"
   },
   "outputs": [],
   "source": [
    "#split the train test dataset\n",
    "train_df, test_df = train_test_split(df_, test_size = 0.2)\n",
    "#split the train validation dataset\n",
    "train_df, val_df = train_test_split(train_df, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Ws3eIXKozWM",
    "outputId": "ec5c1b61-db6c-401d-b5ec-db2683aa535d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 16000 entries, 4981 to 2740\n",
      "Data columns (total 4 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   new_filename           16000 non-null  object \n",
      " 1   diagnostic_superclass  16000 non-null  int64  \n",
      " 2   age                    16000 non-null  float64\n",
      " 3   sex                    16000 non-null  int64  \n",
      "dtypes: float64(1), int64(2), object(1)\n",
      "memory usage: 625.0+ KB\n",
      "None\n",
      "\n",
      "test dataset information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5000 entries, 14057 to 7501\n",
      "Data columns (total 4 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   new_filename           5000 non-null   object \n",
      " 1   diagnostic_superclass  5000 non-null   int64  \n",
      " 2   age                    5000 non-null   float64\n",
      " 3   sex                    5000 non-null   int64  \n",
      "dtypes: float64(1), int64(2), object(1)\n",
      "memory usage: 195.3+ KB\n",
      "None\n",
      "\n",
      "validation dataset information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4000 entries, 20645 to 14531\n",
      "Data columns (total 4 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   new_filename           4000 non-null   object \n",
      " 1   diagnostic_superclass  4000 non-null   int64  \n",
      " 2   age                    4000 non-null   float64\n",
      " 3   sex                    4000 non-null   int64  \n",
      "dtypes: float64(1), int64(2), object(1)\n",
      "memory usage: 156.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"train dataset information:\")\n",
    "print(train_df.info())\n",
    "print()\n",
    "print(\"test dataset information:\")\n",
    "print(test_df.info())\n",
    "print()\n",
    "print(\"validation dataset information:\")\n",
    "print(val_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6cf7DZEHD1R-"
   },
   "source": [
    "# Read data into Tensorflow data pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GZeIvY9m-wUk"
   },
   "source": [
    "TensorFlow Encode and Decode base Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "W-olHnLnD_io"
   },
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    # If the value is an eager tensor BytesList won't unpack a string from an EagerTensor.\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() \n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def save_tfrecords(data, label, sex, age, desfile):\n",
    "    with tf.io.TFRecordWriter(desfile) as writer:\n",
    "      features = tf.train.Features(\n",
    "                feature = {\n",
    "                    \"data\": _bytes_feature(tf.io.serialize_tensor(data)),\n",
    "                    \"label\":_int64_feature(label),\n",
    "                    \"sex\":_int64_feature(sex),\n",
    "                    \"age\":_float_feature(age)\n",
    "                }\n",
    "            )\n",
    "      example = tf.train.Example(features = features)\n",
    "      serialized = example.SerializeToString()\n",
    "      writer.write(serialized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E2NftRX4eys1"
   },
   "source": [
    "**here can load the raw data directly to memory, sampling_rate 100 means the 100hz dataset, physinet provide 100hz dataset for user easier to use but we use 500 hz dataset in our project here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LODeKtYiyLaa"
   },
   "outputs": [],
   "source": [
    "# here can load the raw data directly to memory, sampling_rate 100 means the 100hz dataset, physinet provide 100hz dataset for user easier to use\n",
    "# but we use 500 hz dataset in our project here\n",
    "\n",
    "# def load_raw_data(path):\n",
    "#     print(\"start\")\n",
    "#     sampling_rate = 100\n",
    "#     def aggregate_diagnostic(y_dic):\n",
    "#       tmp = []\n",
    "#       for key in y_dic.keys():\n",
    "#           if key in agg_df.index:\n",
    "#               tmp.append(agg_df.loc[key].diagnostic_class)\n",
    "#       return list(set(tmp))\n",
    "#     # load and convert annotation data\n",
    "#     Y = pd.read_csv(path+'ptbxl_database.csv', index_col='ecg_id')\n",
    "#     Y.scp_codes = Y.scp_codes.apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "#     # Load scp_statements.csv for diagnostic aggregation\n",
    "#     agg_df = pd.read_csv(path+'scp_statements.csv', index_col=0)\n",
    "#     agg_df = agg_df[agg_df.diagnostic == 1]\n",
    "\n",
    "#     # Apply diagnostic superclass\n",
    "#     #target label of the classification\n",
    "#     Y['diagnostic_superclass'] = Y.scp_codes.apply(aggregate_diagnostic)\n",
    "#     print(len(Y.diagnostic_superclass))\n",
    "#     #Y.reset_index()\n",
    "#     # 100 HZ dataset\n",
    "#     # if sampling_rate == 100:\n",
    "#     #     data = [wfdb.rdrecord(path+f).p_signal.T for f in Y.filename_lr]\n",
    "#     #     #print(data)\n",
    "#     # else:\n",
    "#     # 500 HZ array dataset\n",
    "#     for i in range(1,len(Y)+1):\n",
    "#       f = Y.filename_hr[i]\n",
    "#       # print(\"file name:\")\n",
    "#       # print(f)\n",
    "#       sex = Y.sex[i]\n",
    "#       # print(\"sex:\")\n",
    "#       # print(sex)\n",
    "#       age = Y.age[i]\n",
    "#       # print(\"age:\")\n",
    "#       # print(age)\n",
    "#       data =wfdb.rdrecord(path+f).p_signal.T\n",
    "#       # print(\"data:\"+str(i))\n",
    "#       # print(data)\n",
    "#       tf_path = os.path.join(tf_save_path,f+'.tfrecords')\n",
    "#       # print(\"tf_path:\")\n",
    "#       # print(tf_path)\n",
    "#       label = Y.diagnostic_superclass[i]\n",
    "#       # print(\"label:\")\n",
    "#       # print(label)\n",
    "#       save_tfrecords(data,label,sex,age,tf_path)\n",
    "#     #data = [wfdb.rdrecord(path+f).p_signal.T for f in Y.filename_hr]\n",
    "#     #data = np.array([signal for signal, meta in data])\n",
    "#     print('finish')\n",
    "#     return data, Y.diagnostic_superclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "nWlvtRLhsIeC"
   },
   "outputs": [],
   "source": [
    "#tensor flow function\n",
    "def load_data(df,batch_size,i):\n",
    "  #print(file_path)\n",
    "  #df.reindex()\n",
    "  end_index = (i+1)*batch_size\n",
    "  if end_index > df.index[-1]:\n",
    "    end_index = df.index[-1]\n",
    "  start_index = i*batch_size\n",
    "  path_list = df['new_filename'][start_index:end_index]\n",
    "  #print(i)\n",
    "  #age_tensor = tf.constant(df['age'][start_index: end_index],dtype=\"int8\")\n",
    "  #sex_tensor =tf.constant(df['sex'][start_index: end_index],dtype=\"int8\")\n",
    "  #label_one_hot = tf.one_hot(df['diagnostic_superclass'][start_index: end_index],5)\n",
    "  #label_tensor = tf.constant(label_one_hot,dtype=\"float32\")\n",
    "  #file = file_path.numpy().decode('UTF-8')\n",
    "  #print(file)\n",
    "  data_list = []\n",
    "  for j in range(len(path_list)):\n",
    "    #print(len(path_list))\n",
    "    #print(path_list.index[j])\n",
    "    file_path = path_list[path_list.index[j]]\n",
    "    #print(file_path)\n",
    "    data = wfdb.rdrecord(file_path).p_signal.T.astype(\"float16\")\n",
    "    data_list.append(data)\n",
    "  data_array = np.array(data_list)\n",
    "  #dataset = tf.data.Dataset.from_tensor_slices((data_array,age_tensor,sex_tensor,label_tensor))\n",
    "  #set tensorflow feature\n",
    "  label_tensor = tf.constant(train_df['diagnostic_superclass'][start_index: end_index],5)\n",
    "  dataset = tf.data.Dataset.from_tensor_slices((data_array, label_tensor))\n",
    "  return dataset\n",
    "\n",
    "def one_hot_encode(signal,label):\n",
    "    if label == 0:\n",
    "      label = np.array([1.0,.0,.0,.0,.0]).astype(\"float16\")\n",
    "    elif label == 1:\n",
    "      label = np.array([.0,1.0,.0,.0,.0]).astype(\"float16\")\n",
    "    elif label ==3:\n",
    "      label = np.array([.0,.0,1.0,.0,.0]).astype(\"float16\")\n",
    "    elif label ==4:\n",
    "      label = np.array([.0,.0,.0,1.0,.0]).astype(\"float16\")\n",
    "    else: \n",
    "      label = np.array([.0,.0,.0,.0,1.0]).astype(\"float16\")\n",
    "    return signal , label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4uTrT2rYvjyv"
   },
   "source": [
    "# data preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "LtRXFr-qvnKl"
   },
   "outputs": [],
   "source": [
    "import pywt\n",
    "\n",
    "def denoise(sig_data):\n",
    "    # wavedec\n",
    "    coeffs = pywt.wavedec(data=sig_data, wavelet='db8', level=9)\n",
    "    cA9, cD9, cD8, cD7, cD6, cD5, cD4, cD3, cD2, cD1 = coeffs\n",
    "    #print('here')\n",
    "    # threshold\n",
    "    threshold = (np.median(np.abs(cD1)) / 0.6745) * (np.sqrt(2 * np.log(len(cD1))))\n",
    "    cD1.fill(0)\n",
    "    cD2.fill(0)\n",
    "    for i in range(1, len(coeffs) - 2):\n",
    "       coeffs[i] = pywt.threshold(coeffs[i], threshold)\n",
    "\n",
    "    rdata = pywt.waverec(coeffs=coeffs, wavelet='db8')\n",
    "    #print(rdata)\n",
    "    return rdata\n",
    "\n",
    "def denoise_for_tf_data(data,label):\n",
    "  # Generating numpy array \n",
    "  data_array = np.array(data)\n",
    "  #print(data_array)\n",
    "  for i, sig_array in enumerate(data_array):     \n",
    "    #print(type(sig_array))\n",
    "    # plt.figure()\n",
    "    # plt.plot(sig_array[0:1024]) \n",
    "    # plt.show()\n",
    "    #print(type(sig_array))\n",
    "    sig_length = len(sig_array)\n",
    "    sig_array = denoise(sig_array)\n",
    "    #print(sig_array)\n",
    "    #plt.plot(sig_array[0:1024])\n",
    "    #plt.show()\n",
    "    data_array[i] = sig_array[0:sig_length]\n",
    "  #print(data_array.shape)\n",
    "  data = tf.convert_to_tensor(data_array)\n",
    "  #print(data.numpy())\n",
    "  return data,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "f6gQM2ugbsJy"
   },
   "outputs": [],
   "source": [
    "def get_dataset(df,batch_size, i):\n",
    "    dataset = load_data(df, batch_size,i)\n",
    "    ds_one_hot = dataset.map(one_hot_encode)\n",
    "    ds_denoise = ds_one_hot.map(lambda x,y: \n",
    "                              tuple(tf.py_function(denoise_for_tf_data,[x,y],[tf.float64,tf.float16])))\n",
    "    ds_batch = ds_one_hot.batch(32)\n",
    "    return ds_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "-Pq7TTNKeAq6"
   },
   "outputs": [],
   "source": [
    "def show(data, label):\n",
    "  for sig_data in data:\n",
    "    plt.figure()\n",
    "    plt.title(label)\n",
    "    plt.plot(sig_data[0:1024])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NzhEB94VePMS",
    "outputId": "7086401c-972b-4ce4-ae70-3de8fa2523df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_data: [[[ 0.06   0.06   0.06  ... -0.19  -0.19  -0.19 ]\n",
      "  [ 0.05   0.05   0.05  ... -0.155 -0.155 -0.155]\n",
      "  [-0.01  -0.01  -0.01  ...  0.035  0.035  0.035]\n",
      "  ...\n",
      "  [-0.355 -0.355 -0.355 ...  0.135  0.135  0.135]\n",
      "  [-2.574 -2.574 -2.574 ...  0.     0.     0.   ]\n",
      "  [-0.22  -0.22  -0.22  ...  0.2    0.2    0.2  ]]\n",
      "\n",
      " [[-0.085 -0.085 -0.085 ...  0.015  0.015  0.015]\n",
      "  [-0.055 -0.055 -0.055 ...  0.     0.     0.   ]\n",
      "  [ 0.03   0.03   0.03  ... -0.015 -0.015 -0.015]\n",
      "  ...\n",
      "  [-0.285 -0.285 -0.285 ... -0.135 -0.135 -0.135]\n",
      "  [-0.185 -0.185 -0.185 ... -0.085 -0.085 -0.085]\n",
      "  [-0.115 -0.115 -0.115 ... -0.065 -0.065 -0.065]]\n",
      "\n",
      " [[-0.075 -0.075 -0.075 ...  0.015  0.015  0.015]\n",
      "  [-0.085 -0.085 -0.085 ...  0.085  0.085  0.085]\n",
      "  [-0.01  -0.01  -0.01  ...  0.07   0.07   0.07 ]\n",
      "  ...\n",
      "  [-0.145 -0.145 -0.145 ...  0.285  0.285  0.285]\n",
      "  [ 0.14   0.14   0.14  ...  0.03   0.03   0.03 ]\n",
      "  [-0.315 -0.315 -0.315 ...  0.15   0.15   0.15 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.025 -0.025 -0.025 ... -0.12  -0.12  -0.12 ]\n",
      "  [-0.205 -0.205 -0.205 ...  0.065  0.065  0.065]\n",
      "  [-0.18  -0.18  -0.18  ...  0.185  0.185  0.185]\n",
      "  ...\n",
      "  [-0.02  -0.02  -0.02  ...  0.155  0.155  0.155]\n",
      "  [-0.225 -0.225 -0.225 ...  0.17   0.17   0.17 ]\n",
      "  [-0.8   -0.8   -0.8   ...  0.64   0.64   0.64 ]]\n",
      "\n",
      " [[ 0.02   0.02   0.02  ...  0.105  0.105  0.105]\n",
      "  [ 0.165  0.165  0.165 ... -0.07  -0.07  -0.07 ]\n",
      "  [ 0.145  0.145  0.145 ... -0.175 -0.175 -0.175]\n",
      "  ...\n",
      "  [ 1.155  1.155  1.154 ... -0.525 -0.525 -0.525]\n",
      "  [ 0.74   0.74   0.739 ... -0.325 -0.325 -0.325]\n",
      "  [ 0.205  0.205  0.204 ...  0.16   0.16   0.16 ]]\n",
      "\n",
      " [[ 0.075  0.075  0.075 ... -0.115 -0.115 -0.115]\n",
      "  [-0.045 -0.045 -0.045 ... -0.045 -0.045 -0.045]\n",
      "  [-0.12  -0.12  -0.12  ...  0.07   0.07   0.07 ]\n",
      "  ...\n",
      "  [ 0.3    0.3    0.3   ...  0.38   0.38   0.38 ]\n",
      "  [ 0.075  0.075  0.075 ... -0.075 -0.075 -0.075]\n",
      "  [-0.015 -0.015 -0.015 ... -0.25  -0.25  -0.25 ]]] shape: (32, 12, 5000) \n",
      " batcah_labels: [[1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]] shape: (32, 5)\n"
     ]
    }
   ],
   "source": [
    "# test function\n",
    "ds_test0 = get_dataset(train_df,100, 0)\n",
    "def show_dataset(dataset):\n",
    "  iterator = iter(dataset)\n",
    "  raw_example = next(iterator)\n",
    "  parsed_data = raw_example[0].numpy()\n",
    "  label = raw_example[1].numpy()\n",
    "  print('batch_data:',parsed_data, 'shape:', parsed_data.shape, '\\n batcah_labels:',label, 'shape:', label.shape)\n",
    "\n",
    "show_dataset(ds_test0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6bfETUsDVlf"
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zYa0uuLZH8BD"
   },
   "outputs": [],
   "source": [
    "# %tensorflow_version 2.x\n",
    "# import tensorflow as tf\n",
    "# print(\"Tensorflow version \" + tf.__version__)\n",
    "\n",
    "# try:\n",
    "#   tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
    "#   print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
    "# except ValueError:\n",
    "#   raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
    "\n",
    "# tf.config.experimental_connect_to_cluster(tpu)\n",
    "# tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "# tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "Syw2LfRZtxQN"
   },
   "outputs": [],
   "source": [
    "def buildModel():\n",
    "\n",
    "    newModel = tf.keras.models.Sequential([\n",
    "                                           \n",
    "        tf.keras.layers.InputLayer(input_shape=(12,5000)),\n",
    "\n",
    "        tf.keras.layers.Conv1D(filters=4, kernel_size=21, strides=1, padding='SAME', activation='relu'),\n",
    "       \n",
    "        tf.keras.layers.AvgPool1D(pool_size=1, strides=4, padding='SAME'),\n",
    "        \n",
    "        tf.keras.layers.Conv1D(filters=16, kernel_size=23, strides=1, padding='SAME', activation='relu'),\n",
    "        \n",
    "        tf.keras.layers.AvgPool1D(pool_size=1, strides=4, padding='SAME'),\n",
    "       \n",
    "        tf.keras.layers.Conv1D(filters=32, kernel_size=25, strides=1, padding='SAME', activation='elu'),\n",
    "       \n",
    "        tf.keras.layers.AvgPool1D(pool_size=1, strides=8, padding='SAME'),\n",
    "       \n",
    "        tf.keras.layers.Conv1D(filters=64, kernel_size=27, strides=1, padding='SAME', activation='relu'),\n",
    "       \n",
    "        tf.keras.layers.Flatten(),\n",
    "       \n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "       \n",
    "        tf.keras.layers.Dropout(rate=0.2),\n",
    "       \n",
    "        tf.keras.layers.Dense(5, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # newModel.compile(optimizer = 'adam' , \n",
    "    #               loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return newModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nQWFhnIK8ga1",
    "outputId": "552c9f74-80e9-4767-8793-246f688274a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_12 (Conv1D)           (None, 12, 4)             420004    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_9 (Average (None, 3, 4)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 3, 16)             1488      \n",
      "_________________________________________________________________\n",
      "average_pooling1d_10 (Averag (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 1, 32)             12832     \n",
      "_________________________________________________________________\n",
      "average_pooling1d_11 (Averag (None, 1, 32)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 1, 64)             55360     \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 498,649\n",
      "Trainable params: 498,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# with tpu_strategy.scope():\n",
    "model_test = buildModel()\n",
    "model_test.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NTpOtTTNt04v",
    "outputId": "7fced03a-3bad-466c-a853-7f34b6fd91ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "  #tbcb = keras.callbacks.TensorBoard(log_dir='./Graph', histogram_freq=0,  write_graph=True, write_images=True)\n",
    "%load_ext tensorboard\n",
    "\n",
    "log_dir = \"logs/fit_Feb26/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "model_test.compile(optimizer = 'adam', \n",
    "                  loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wa7tD6Dpklim"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "Ev7iyZ75Oj8n"
   },
   "outputs": [],
   "source": [
    "def train_model(train_df,batch_size , epochs):\n",
    "  for i in range(int(len(train_df)/batch_size)+1):\n",
    "    print('round:', i)  \n",
    "    ds_batch = get_dataset(train_df,batch_size,i)\n",
    "    train_prefetch = ds_batch.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    train_cache = train_prefetch.cache()\n",
    "    model_test.fit(train_cache, epochs=epochs,callbacks = [tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UzrDeEogGSvs",
    "outputId": "c45d1eb6-a713-471c-92fa-9217f08576f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6141     1\n",
       "14978    1\n",
       "4759     1\n",
       "6806     1\n",
       "661      1\n",
       "        ..\n",
       "23809    1\n",
       "21760    1\n",
       "1274     1\n",
       "7417     1\n",
       "2049     1\n",
       "Length: 16000, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.index.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 562
    },
    "id": "vskyF-FCSIza",
    "outputId": "a430d2c6-c0fc-4b77-be6b-95ba187d5d96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round: 0\n",
      "16/16 [==============================] - 1s 13ms/step - loss: 1.6082 - accuracy: 0.2401\n",
      "round: 1\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.6062 - accuracy: 0.2227\n",
      "round: 2\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.6094 - accuracy: 0.1895\n",
      "round: 3\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5944 - accuracy: 0.2344\n",
      "round: 4\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5907 - accuracy: 0.2344\n",
      "round: 5\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 1.5950 - accuracy: 0.2111\n",
      "round: 6\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-2f0db8ea0d52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-100-13e6b47a5f08>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_df, batch_size, epochs)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrain_prefetch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtrain_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_prefetch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mmodel_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_cache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtensorboard_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expect x to be a non-empty array or dataset.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expect x to be a non-empty array or dataset."
     ]
    }
   ],
   "source": [
    "train_model(train_df, 512, 1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Copy of Jacky_ECG_2020.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
